{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2626e74",
   "metadata": {
    "_cell_guid": "01a137bc-ec6b-487a-9c1b-161ff4e2830c",
    "_uuid": "f6d4dd2e-adb1-4ad2-9b78-866bfe3c256c",
    "execution": {
     "iopub.execute_input": "2022-01-29T20:41:36.925655Z",
     "iopub.status.busy": "2022-01-29T20:41:36.923875Z",
     "iopub.status.idle": "2022-01-29T22:13:36.496356Z",
     "shell.execute_reply": "2022-01-29T22:13:36.496798Z",
     "shell.execute_reply.started": "2022-01-29T19:09:26.452854Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 5519.583591,
     "end_time": "2022-01-29T22:13:36.497088",
     "exception": false,
     "start_time": "2022-01-29T20:41:36.913497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-29 20:41:41.953871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 20:41:42.067394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 20:41:42.068216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 20:41:42.069647: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-29 20:41:42.070796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 20:41:42.071592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 20:41:42.072323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 20:41:43.847893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 20:41:43.848831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 20:41:43.849564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-29 20:41:43.850211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create YOLOv3 model with 9 anchors and 4 classes.\n",
      "Load weights ../input/d/raminanush/model-data/model_data/yolo.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n",
      "[[20. 20.]\n",
      " [25. 30.]\n",
      " [30. 25.]\n",
      " [35. 20.]\n",
      " [40. 20.]\n",
      " [45. 35.]\n",
      " [50. 35.]\n",
      " [50. 40.]\n",
      " [60. 35.]]\n",
      "4\n",
      "Tensor(\"yolo_loss/sub:0\", shape=(None, 2, 8, 3, 2), dtype=float32)\n",
      "Tensor(\"yolo_loss/strided_slice_26:0\", shape=(None, None, None, 3, 2), dtype=float32)\n",
      "Tensor(\"yolo_loss/sub_5:0\", shape=(None, 4, 16, 3, 2), dtype=float32)\n",
      "Tensor(\"yolo_loss/strided_slice_53:0\", shape=(None, None, None, 3, 2), dtype=float32)\n",
      "Tensor(\"yolo_loss/sub_10:0\", shape=(None, 8, 32, 3, 2), dtype=float32)\n",
      "Tensor(\"yolo_loss/strided_slice_80:0\", shape=(None, None, None, 3, 2), dtype=float32)\n",
      "Tensor(\"yolo_loss/sub:0\", shape=(None, 2, 8, 3, 2), dtype=float32)\n",
      "Tensor(\"yolo_loss/strided_slice_26:0\", shape=(None, None, None, 3, 2), dtype=float32)\n",
      "Tensor(\"yolo_loss/sub_5:0\", shape=(None, 4, 16, 3, 2), dtype=float32)\n",
      "Tensor(\"yolo_loss/strided_slice_53:0\", shape=(None, None, None, 3, 2), dtype=float32)\n",
      "Tensor(\"yolo_loss/sub_10:0\", shape=(None, 8, 32, 3, 2), dtype=float32)\n",
      "Tensor(\"yolo_loss/strided_slice_80:0\", shape=(None, None, None, 3, 2), dtype=float32)\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 3 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, None, None, 3 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, None, None, 3 0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 6 18432       zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 6 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 2048        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, None, 6 0           leaky_re_lu_1[0][0]              \n",
      "                                                                 leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, None, None, 6 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 1 73728       zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 1 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 6 8192        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 6 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 1 512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 1 0           leaky_re_lu_4[0][0]              \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 6 8192        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 6 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 1 512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 1 0           add_1[0][0]                      \n",
      "                                                                 leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, None, None, 1 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 2 294912      zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 2 1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, None, None, 2 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 1 512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 2 1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 2 0           leaky_re_lu_9[0][0]              \n",
      "                                                                 leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 1 32768       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 1 512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 2 1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 2 0           add_3[0][0]                      \n",
      "                                                                 leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 1 32768       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 1 512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 2 1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 2 0           add_4[0][0]                      \n",
      "                                                                 leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 1 32768       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 1 512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 2 1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 2 0           add_5[0][0]                      \n",
      "                                                                 leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 1 32768       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 1 512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 2 1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 2 0           add_6[0][0]                      \n",
      "                                                                 leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 1 32768       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 1 512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 2 1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 2 0           add_7[0][0]                      \n",
      "                                                                 leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 1 32768       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 1 512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 2 1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 2 0           add_8[0][0]                      \n",
      "                                                                 leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 1 32768       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 1 512         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 2 1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 2 0           add_9[0][0]                      \n",
      "                                                                 leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, None, None, 2 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 5 1179648     zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 5 2048        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 2 1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 5 2048        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 5 0           leaky_re_lu_26[0][0]             \n",
      "                                                                 leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 2 131072      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 2 1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 5 2048        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, None, 5 0           add_11[0][0]                     \n",
      "                                                                 leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 2 131072      add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 2 1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 5 2048        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, None, None, 5 0           add_12[0][0]                     \n",
      "                                                                 leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 2 131072      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 2 1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 5 2048        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, None, 5 0           add_13[0][0]                     \n",
      "                                                                 leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 2 131072      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 2 1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 5 2048        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, None, 5 0           add_14[0][0]                     \n",
      "                                                                 leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 2 131072      add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 2 1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 5 2048        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, None, 5 0           add_15[0][0]                     \n",
      "                                                                 leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 2 131072      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 2 1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 5 2048        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, None, 5 0           add_16[0][0]                     \n",
      "                                                                 leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 2 131072      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 2 1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 5 2048        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, None, 5 0           add_17[0][0]                     \n",
      "                                                                 leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, None, None, 5 0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 4718592     zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 4096        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 5 2048        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 4096        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, None, 1 0           leaky_re_lu_43[0][0]             \n",
      "                                                                 leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 5 524288      add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 5 2048        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 4096        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, None, None, 1 0           add_19[0][0]                     \n",
      "                                                                 leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 5 524288      add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 5 2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 4096        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, None, 1 0           add_20[0][0]                     \n",
      "                                                                 leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 5 524288      add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 5 2048        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 4096        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, None, 1 0           add_21[0][0]                     \n",
      "                                                                 leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 5 524288      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 5 2048        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 4096        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 5 2048        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 4096        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 5 2048        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 2 1024        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, None, None, 2 0           leaky_re_lu_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, None, 7 0           up_sampling2d[0][0]              \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 2 196608      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 2 1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 5 2048        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 2 1024        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 5 2048        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 2 1024        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 512         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 3 0           up_sampling2d_1[0][0]            \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 49152       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 2 1024        conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 512         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 2 1024        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 4096        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 5 2048        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 2 1024        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 2 27675       leaky_re_lu_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 2 13851       leaky_re_lu_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 2 6939        leaky_re_lu_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2, 8, 3, 9)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 4, 16, 3, 9) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 8, 32, 3, 9) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "yolo_loss (Lambda)              ()                   0           conv2d_58[0][0]                  \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "                                                                 conv2d_74[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 61,592,497\n",
      "Trainable params: 48,465\n",
      "Non-trainable params: 61,544,032\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Starting at Stage 1, loading ../input/trained-weights/trained_weights_stage_0_mouse.h5\n",
      "Unfreeze all of the layers.\n",
      "Train on 25433 samples, val on 2825 samples, with batch size 64.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-29 20:41:55.628584: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Tensor(\"model_5/yolo_loss/sub:0\", shape=(None, 2, 8, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/strided_slice_26:0\", shape=(None, None, None, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/sub_5:0\", shape=(None, 4, 16, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/strided_slice_53:0\", shape=(None, None, None, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/sub_10:0\", shape=(None, 8, 32, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/strided_slice_80:0\", shape=(None, None, None, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/sub:0\", shape=(None, 2, 8, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/strided_slice_26:0\", shape=(None, None, None, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/sub_5:0\", shape=(None, 4, 16, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/strided_slice_53:0\", shape=(None, None, None, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/sub_10:0\", shape=(None, 8, 32, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/strided_slice_80:0\", shape=(None, None, None, 3, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-29 20:42:04.146169: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] layout failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
      "2022-01-29 20:42:05.976345: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - ETA: 0s - loss: 19.8440Tensor(\"model_5/yolo_loss/sub:0\", shape=(None, 2, 8, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/strided_slice_26:0\", shape=(None, None, None, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/sub_5:0\", shape=(None, 4, 16, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/strided_slice_53:0\", shape=(None, None, None, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/sub_10:0\", shape=(None, 8, 32, 3, 2), dtype=float32)\n",
      "Tensor(\"model_5/yolo_loss/strided_slice_80:0\", shape=(None, None, None, 3, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-29 20:47:06.117358: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] layout failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
      "2022-01-29 20:47:06.136912: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
      "2022-01-29 20:47:06.303694: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - 340s 816ms/step - loss: 19.8440 - val_loss: 17.0313\n",
      "Epoch 2/30\n",
      "397/397 [==============================] - 190s 478ms/step - loss: 17.7516 - val_loss: 15.9155\n",
      "Epoch 3/30\n",
      "397/397 [==============================] - 190s 480ms/step - loss: 16.4926 - val_loss: 15.0535\n",
      "Epoch 4/30\n",
      "397/397 [==============================] - 191s 482ms/step - loss: 15.4289 - val_loss: 14.5728\n",
      "Epoch 5/30\n",
      "397/397 [==============================] - 192s 483ms/step - loss: 14.5192 - val_loss: 13.9960\n",
      "Epoch 6/30\n",
      "397/397 [==============================] - 192s 485ms/step - loss: 13.7487 - val_loss: 13.4214\n",
      "Epoch 7/30\n",
      "397/397 [==============================] - 193s 487ms/step - loss: 13.1074 - val_loss: 13.6154\n",
      "Epoch 8/30\n",
      "397/397 [==============================] - 193s 486ms/step - loss: 12.4904 - val_loss: 13.2413\n",
      "Epoch 9/30\n",
      "397/397 [==============================] - 195s 491ms/step - loss: 12.0243 - val_loss: 13.2690\n",
      "Epoch 10/30\n",
      "397/397 [==============================] - 194s 489ms/step - loss: 11.5779 - val_loss: 14.1512\n",
      "Epoch 11/30\n",
      "397/397 [==============================] - 194s 490ms/step - loss: 11.1195 - val_loss: 13.2228\n",
      "Epoch 12/30\n",
      "397/397 [==============================] - 196s 495ms/step - loss: 10.8286 - val_loss: 14.0082\n",
      "Epoch 13/30\n",
      "397/397 [==============================] - 196s 494ms/step - loss: 10.5292 - val_loss: 13.5819\n",
      "Epoch 14/30\n",
      "397/397 [==============================] - 196s 495ms/step - loss: 10.2521 - val_loss: 12.5675\n",
      "Epoch 15/30\n",
      "397/397 [==============================] - 201s 506ms/step - loss: 9.9972 - val_loss: 12.7189\n",
      "Epoch 16/30\n",
      "397/397 [==============================] - 200s 505ms/step - loss: 9.7945 - val_loss: 12.9392\n",
      "Epoch 17/30\n",
      "397/397 [==============================] - 199s 500ms/step - loss: 9.6284 - val_loss: 12.4057\n",
      "Epoch 18/30\n",
      "397/397 [==============================] - 201s 508ms/step - loss: 9.4187 - val_loss: 12.4695\n",
      "Epoch 19/30\n",
      "397/397 [==============================] - 202s 509ms/step - loss: 9.2259 - val_loss: 12.5814\n",
      "Epoch 20/30\n",
      "397/397 [==============================] - 199s 503ms/step - loss: 9.1202 - val_loss: 13.6449\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 21/30\n",
      "397/397 [==============================] - 203s 512ms/step - loss: 9.1370 - val_loss: 12.7837\n",
      "Epoch 22/30\n",
      "397/397 [==============================] - 201s 506ms/step - loss: 8.7818 - val_loss: 13.1388\n",
      "Epoch 23/30\n",
      "397/397 [==============================] - 203s 511ms/step - loss: 8.6169 - val_loss: 13.5339\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 24/30\n",
      "397/397 [==============================] - 201s 507ms/step - loss: 8.6749 - val_loss: 14.5175\n",
      "Epoch 25/30\n",
      "397/397 [==============================] - 204s 515ms/step - loss: 8.5731 - val_loss: 14.5567\n",
      "Epoch 26/30\n",
      "397/397 [==============================] - 203s 511ms/step - loss: 8.5338 - val_loss: 14.4400\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 27/30\n",
      "397/397 [==============================] - 205s 516ms/step - loss: 8.5145 - val_loss: 14.3785\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrain the YOLO model for your own dataset.\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "import keras\n",
    "from scripts.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from scripts.utils import get_random_data\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "def _main():\n",
    "    ext = 'mouse'\n",
    "    annotation_path = '../input/mouse-walking-data/train.txt' # if this changes, the bottlenecks will need to be updated first\n",
    "    log_dir      = './logs/'\n",
    "    bott_dir = '../input/bottlenecks/logs/'\n",
    "    save_path = './'\n",
    "    weight_path = '../input/trained-weights/'\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    classes_path = '../input/model-data/model_data/mouse_classes.txt'\n",
    "    anchors_path = '../input/model-data/model_data/yolo_anchors_mouse.txt'\n",
    "    class_names  = get_classes(classes_path)\n",
    "    num_classes  = len(class_names)\n",
    "    anchors = get_anchors(anchors_path)\n",
    "\n",
    "    training_stage = 1# you need to start from 0 if train.txt is changed\n",
    "    # specify where the training should start (0 is from bottlenecks, 1 is from a draft model)\n",
    "    \n",
    "    input_shape = (64,256) # multiple of 32, hw # must match existing bottlenecks if it's being used\n",
    "\n",
    "    model, bottleneck_model, last_layer_model = create_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='../input/model-data/model_data/yolo.h5') # make sure you know what you freeze\n",
    "\n",
    "    checkpoint = ModelCheckpoint(log_dir , monitor='val_loss', save_weights_only=True, save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "    val_split = 0.1\n",
    "    \n",
    "    with open(annotation_path) as f:\n",
    "        all_lines = f.readlines()\n",
    "    \n",
    "    num_val = int(len(all_lines)*val_split)\n",
    "    num_train = len(all_lines) - num_val\n",
    "\n",
    "    # Train with frozen layers first, to get a stable loss.\n",
    "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
    "    # perform bottleneck training\n",
    "    if training_stage == -1 :\n",
    "        print(\"calculating bottlenecks\")\n",
    "        b = [0 , 1024]\n",
    "        batch_size=32\n",
    "        count = 0\n",
    "        while b[1] < len(all_lines):\n",
    "            print(count)\n",
    "            lines = all_lines[b[0]:b[1]]\n",
    "            bottlenecks = bottleneck_model.predict(data_generator_wrapper(lines, batch_size, input_shape, anchors, num_classes, random=True, verbose=True),steps=(len(lines)//batch_size)+1, max_queue_size=1)\n",
    "            pickle.dump(bottlenecks[0], open(log_dir + \"bottlenecks_\"  + str(count) + ext + \"0.pickle\",'wb'))\n",
    "            pickle.dump(bottlenecks[1], open(log_dir + \"bottlenecks_\"  + str(count) + ext + \"1.pickle\",'wb'))\n",
    "            pickle.dump(bottlenecks[2], open(log_dir + \"bottlenecks_\"  + str(count) + ext + \"2.pickle\",'wb'))\n",
    "            b[0] += 1024\n",
    "            b[1] += 1024\n",
    "            count += 1\n",
    "\n",
    "    batch_size=32\n",
    "    \n",
    "    if training_stage == -1 :\n",
    "        bott_dir = log_dir\n",
    "\n",
    "        \n",
    "    if training_stage <= 0 :\n",
    "        b = [0 , 1024]\n",
    "        last_layer_model.compile(optimizer=adam_v2.Adam(0.00005), loss={'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "        count = 0\n",
    "        while b[1] < len(all_lines):\n",
    "            print(count)\n",
    "            lines = all_lines[b[0]:b[1]]\n",
    "            \n",
    "            b[0] += 1024\n",
    "            b[1] += 1024\n",
    "            \n",
    "            num_val = int(len(lines)*val_split)\n",
    "            num_train = len(lines) - num_val\n",
    "            \n",
    "            dict_bot0 = pickle.load(open(bott_dir + \"bottlenecks_\" + str(count)+ ext + \"0.pickle\",'rb'))\n",
    "            dict_bot1 = pickle.load(open(bott_dir + \"bottlenecks_\" + str(count)+ ext + \"1.pickle\",'rb'))\n",
    "            dict_bot2 = pickle.load(open(bott_dir + \"bottlenecks_\" + str(count)+ ext + \"2.pickle\",'rb'))\n",
    "            dict_bot = {\"bot0\":dict_bot0,\"bot1\":dict_bot1,\"bot2\":dict_bot2}\n",
    "            \n",
    "            bottlenecks_train=[dict_bot[\"bot0\"][:num_train], dict_bot[\"bot1\"][:num_train], dict_bot[\"bot2\"][:num_train]]\n",
    "\n",
    "            bottlenecks_val=[dict_bot[\"bot0\"][num_train:], dict_bot[\"bot1\"][num_train:], dict_bot[\"bot2\"][num_train:]]\n",
    "            \n",
    "            print(\"Training last layers with bottleneck features : \" + str(count))\n",
    "            print('with {} samples, val on {} samples and batch size {}.'.format(num_train, num_val, batch_size) , end = '\\r')\n",
    "            \n",
    "            \n",
    "            last_layer_model.fit(bottleneck_generator(lines[:num_train], batch_size, input_shape, anchors, num_classes, bottlenecks_train, random_=True),\n",
    "                    steps_per_epoch=max(1, num_train//batch_size),\n",
    "                    validation_data=bottleneck_generator(lines[num_train:], batch_size, input_shape, anchors, num_classes, bottlenecks_val, random_=True),\n",
    "                    validation_steps=max(1, num_val//batch_size),epochs=20,initial_epoch=0, max_queue_size=1)\n",
    "            \n",
    "            del(dict_bot)\n",
    "            del(dict_bot0)\n",
    "            del(dict_bot1)\n",
    "            del(dict_bot2)\n",
    "            del(bottlenecks_val)\n",
    "            del(bottlenecks_train)\n",
    "            del(lines)\n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            if count > 16:\n",
    "                break\n",
    "            \n",
    "        model.save_weights(log_dir + 'trained_weights_stage_0_'  + ext + '.h5')\n",
    "\n",
    "    # Unfreeze and continue training, to fine-tune.\n",
    "    # Train longer if the result is not good.\n",
    "    if training_stage == 0 :\n",
    "        weight_path_ = log_dir + 'trained_weights_stage_0_'  + ext + '.h5'\n",
    "        print(\"loading from log, Stage 1 \" + weight_path_)\n",
    "        model.load_weights(weight_path_)\n",
    "        \n",
    "    else:\n",
    "        print(model.summary())\n",
    "        weight_path_ = weight_path + 'trained_weights_stage_0_'  + ext + '.h5'\n",
    "        print(\"Starting at Stage 1, loading \" + weight_path_)\n",
    "        model.load_weights(weight_path_)\n",
    "\n",
    "        \n",
    "    print('Unfreeze all of the layers.')\n",
    "    for i in range(len(model.layers)):\n",
    "        model.layers[i].trainable = True\n",
    "        \n",
    "    model.compile(optimizer= adam_v2.Adam(0.0001), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "\n",
    "    batch_size = 64 # note that more GPU memory is required after unfreezing the body\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "\n",
    "    model.fit(data_generator_wrapper(all_lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(all_lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=30,\n",
    "            initial_epoch=0,\n",
    "            callbacks=[checkpoint, reduce_lr, early_stopping])\n",
    "\n",
    "    model.save_weights(log_dir + 'trained_weights_final_'  + ext + '.h5')\n",
    "\n",
    "\n",
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='../input/model-data/model_data/yolo_weights.h5'):\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    # get output of second last layers and create bottleneck model of it\n",
    "    out1=model_body.layers[246].output\n",
    "    out2=model_body.layers[247].output\n",
    "    out3=model_body.layers[248].output\n",
    "    bottleneck_model = Model([model_body.input, *y_true], [out1, out2, out3])\n",
    "\n",
    "    # create last layer model of last layers from yolo model\n",
    "    in0 = Input(shape=bottleneck_model.output[0].shape[1:].as_list())\n",
    "    in1 = Input(shape=bottleneck_model.output[1].shape[1:].as_list())\n",
    "    in2 = Input(shape=bottleneck_model.output[2].shape[1:].as_list())\n",
    "    last_out0=model_body.layers[249](in0)\n",
    "    last_out1=model_body.layers[250](in1)\n",
    "    last_out2=model_body.layers[251](in2)\n",
    "    model_last=Model(inputs=[in0, in1, in2], outputs=[last_out0, last_out1, last_out2])\n",
    "    print(anchors)\n",
    "    print(num_classes)\n",
    "    model_loss_last =Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_last.output, *y_true])\n",
    "    last_layer_model = Model([in0,in1,in2, *y_true], model_loss_last)\n",
    "\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model, bottleneck_model, last_layer_model\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes, random=False, verbose=False):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0 and random:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=random)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        if verbose:\n",
    "            print(\"Progress: \",i,\"/\",n)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes, random=False, verbose=False):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes, random, verbose)\n",
    "\n",
    "def bottleneck_generator(annotation_lines, batch_size, input_shape, anchors, num_classes, bottlenecks,random_=False):\n",
    "    n = len(annotation_lines)\n",
    "    print(n)\n",
    "    i = 0\n",
    "    while True:\n",
    "        box_data = []\n",
    "        b0=np.zeros((batch_size,bottlenecks[0].shape[1],bottlenecks[0].shape[2],bottlenecks[0].shape[3]))\n",
    "        b1=np.zeros((batch_size,bottlenecks[1].shape[1],bottlenecks[1].shape[2],bottlenecks[1].shape[3]))\n",
    "        b2=np.zeros((batch_size,bottlenecks[2].shape[1],bottlenecks[2].shape[2],bottlenecks[2].shape[3]))\n",
    "        for b in range(batch_size):\n",
    "            _, box = get_random_data(annotation_lines[i], input_shape, random=random_)\n",
    "            box_data.append(box)\n",
    "            b0[b]=bottlenecks[0][i]\n",
    "            b1[b]=bottlenecks[1][i]\n",
    "            b2[b]=bottlenecks[2][i]\n",
    "            i = (i+1) % n\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [b0, b1, b2, *y_true], np.zeros(batch_size)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    _main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40d89b",
   "metadata": {
    "papermill": {
     "duration": 3.03313,
     "end_time": "2022-01-29T22:15:03.825081",
     "exception": false,
     "start_time": "2022-01-29T22:15:00.791951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5621.193263,
   "end_time": "2022-01-29T22:15:09.388341",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-29T20:41:28.195078",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
